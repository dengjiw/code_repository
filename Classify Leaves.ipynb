{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入需要的包\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from d2l import torch as d2l\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/0.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/1.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/2.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/3.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/4.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>images/5.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          image             label\n",
       "0  images/0.jpg  maclura_pomifera\n",
       "1  images/1.jpg  maclura_pomifera\n",
       "2  images/2.jpg  maclura_pomifera\n",
       "3  images/3.jpg  maclura_pomifera\n",
       "4  images/4.jpg  maclura_pomifera\n",
       "5  images/5.jpg  maclura_pomifera"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取csv数据\n",
    "train_data = pd.read_csv('../data/train.csv')\n",
    "train_data[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abies_concolor',\n",
       " 'abies_nordmanniana',\n",
       " 'acer_campestre',\n",
       " 'acer_ginnala',\n",
       " 'acer_griseum']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#给类别排序\n",
    "labels = sorted(list(set(train_data['label'])))\n",
    "labels_len = len(labels)\n",
    "print(labels_len)\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abies_concolor': 0, 'abies_nordmanniana': 1, 'acer_campestre': 2, 'acer_ginnala': 3, 'acer_griseum': 4, 'acer_negundo': 5, 'acer_palmatum': 6, 'acer_pensylvanicum': 7, 'acer_platanoides': 8, 'acer_pseudoplatanus': 9, 'acer_rubrum': 10, 'acer_saccharinum': 11, 'acer_saccharum': 12, 'aesculus_flava': 13, 'aesculus_glabra': 14, 'aesculus_hippocastamon': 15, 'aesculus_pavi': 16, 'ailanthus_altissima': 17, 'albizia_julibrissin': 18, 'amelanchier_arborea': 19, 'amelanchier_canadensis': 20, 'amelanchier_laevis': 21, 'asimina_triloba': 22, 'betula_alleghaniensis': 23, 'betula_jacqemontii': 24, 'betula_lenta': 25, 'betula_nigra': 26, 'betula_populifolia': 27, 'broussonettia_papyrifera': 28, 'carpinus_betulus': 29, 'carpinus_caroliniana': 30, 'carya_cordiformis': 31, 'carya_glabra': 32, 'carya_ovata': 33, 'carya_tomentosa': 34, 'castanea_dentata': 35, 'catalpa_bignonioides': 36, 'catalpa_speciosa': 37, 'cedrus_atlantica': 38, 'cedrus_deodara': 39, 'cedrus_libani': 40, 'celtis_occidentalis': 41, 'celtis_tenuifolia': 42, 'cercidiphyllum_japonicum': 43, 'cercis_canadensis': 44, 'chamaecyparis_pisifera': 45, 'chamaecyparis_thyoides': 46, 'chionanthus_retusus': 47, 'chionanthus_virginicus': 48, 'cladrastis_lutea': 49, 'cornus_florida': 50, 'cornus_kousa': 51, 'cornus_mas': 52, 'crataegus_crus-galli': 53, 'crataegus_laevigata': 54, 'crataegus_phaenopyrum': 55, 'crataegus_pruinosa': 56, 'crataegus_viridis': 57, 'cryptomeria_japonica': 58, 'diospyros_virginiana': 59, 'eucommia_ulmoides': 60, 'evodia_daniellii': 61, 'fagus_grandifolia': 62, 'ficus_carica': 63, 'fraxinus_nigra': 64, 'fraxinus_pennsylvanica': 65, 'ginkgo_biloba': 66, 'gleditsia_triacanthos': 67, 'gymnocladus_dioicus': 68, 'halesia_tetraptera': 69, 'ilex_opaca': 70, 'juglans_cinerea': 71, 'juglans_nigra': 72, 'juniperus_virginiana': 73, 'koelreuteria_paniculata': 74, 'larix_decidua': 75, 'liquidambar_styraciflua': 76, 'liriodendron_tulipifera': 77, 'maclura_pomifera': 78, 'magnolia_acuminata': 79, 'magnolia_denudata': 80, 'magnolia_grandiflora': 81, 'magnolia_macrophylla': 82, 'magnolia_stellata': 83, 'magnolia_tripetala': 84, 'magnolia_virginiana': 85, 'malus_baccata': 86, 'malus_coronaria': 87, 'malus_floribunda': 88, 'malus_hupehensis': 89, 'malus_pumila': 90, 'metasequoia_glyptostroboides': 91, 'morus_alba': 92, 'morus_rubra': 93, 'nyssa_sylvatica': 94, 'ostrya_virginiana': 95, 'oxydendrum_arboreum': 96, 'paulownia_tomentosa': 97, 'phellodendron_amurense': 98, 'picea_abies': 99, 'picea_orientalis': 100, 'picea_pungens': 101, 'pinus_bungeana': 102, 'pinus_cembra': 103, 'pinus_densiflora': 104, 'pinus_echinata': 105, 'pinus_flexilis': 106, 'pinus_koraiensis': 107, 'pinus_nigra': 108, 'pinus_parviflora': 109, 'pinus_peucea': 110, 'pinus_pungens': 111, 'pinus_resinosa': 112, 'pinus_rigida': 113, 'pinus_strobus': 114, 'pinus_sylvestris': 115, 'pinus_taeda': 116, 'pinus_thunbergii': 117, 'pinus_virginiana': 118, 'pinus_wallichiana': 119, 'platanus_acerifolia': 120, 'platanus_occidentalis': 121, 'populus_deltoides': 122, 'populus_grandidentata': 123, 'populus_tremuloides': 124, 'prunus_pensylvanica': 125, 'prunus_sargentii': 126, 'prunus_serotina': 127, 'prunus_serrulata': 128, 'prunus_subhirtella': 129, 'prunus_virginiana': 130, 'prunus_yedoensis': 131, 'pseudolarix_amabilis': 132, 'ptelea_trifoliata': 133, 'pyrus_calleryana': 134, 'quercus_acutissima': 135, 'quercus_alba': 136, 'quercus_bicolor': 137, 'quercus_cerris': 138, 'quercus_coccinea': 139, 'quercus_imbricaria': 140, 'quercus_macrocarpa': 141, 'quercus_marilandica': 142, 'quercus_michauxii': 143, 'quercus_montana': 144, 'quercus_muehlenbergii': 145, 'quercus_nigra': 146, 'quercus_palustris': 147, 'quercus_phellos': 148, 'quercus_robur': 149, 'quercus_shumardii': 150, 'quercus_stellata': 151, 'quercus_velutina': 152, 'quercus_virginiana': 153, 'robinia_pseudo-acacia': 154, 'salix_babylonica': 155, 'salix_caroliniana': 156, 'salix_matsudana': 157, 'salix_nigra': 158, 'sassafras_albidum': 159, 'staphylea_trifolia': 160, 'stewartia_pseudocamellia': 161, 'styrax_japonica': 162, 'taxodium_distichum': 163, 'tilia_americana': 164, 'tilia_cordata': 165, 'tilia_europaea': 166, 'tilia_tomentosa': 167, 'tsuga_canadensis': 168, 'ulmus_americana': 169, 'ulmus_glabra': 170, 'ulmus_parvifolia': 171, 'ulmus_procera': 172, 'ulmus_pumila': 173, 'ulmus_rubra': 174, 'zelkova_serrata': 175}\n",
      "{0: 'abies_concolor', 1: 'abies_nordmanniana', 2: 'acer_campestre', 3: 'acer_ginnala', 4: 'acer_griseum', 5: 'acer_negundo', 6: 'acer_palmatum', 7: 'acer_pensylvanicum', 8: 'acer_platanoides', 9: 'acer_pseudoplatanus', 10: 'acer_rubrum', 11: 'acer_saccharinum', 12: 'acer_saccharum', 13: 'aesculus_flava', 14: 'aesculus_glabra', 15: 'aesculus_hippocastamon', 16: 'aesculus_pavi', 17: 'ailanthus_altissima', 18: 'albizia_julibrissin', 19: 'amelanchier_arborea', 20: 'amelanchier_canadensis', 21: 'amelanchier_laevis', 22: 'asimina_triloba', 23: 'betula_alleghaniensis', 24: 'betula_jacqemontii', 25: 'betula_lenta', 26: 'betula_nigra', 27: 'betula_populifolia', 28: 'broussonettia_papyrifera', 29: 'carpinus_betulus', 30: 'carpinus_caroliniana', 31: 'carya_cordiformis', 32: 'carya_glabra', 33: 'carya_ovata', 34: 'carya_tomentosa', 35: 'castanea_dentata', 36: 'catalpa_bignonioides', 37: 'catalpa_speciosa', 38: 'cedrus_atlantica', 39: 'cedrus_deodara', 40: 'cedrus_libani', 41: 'celtis_occidentalis', 42: 'celtis_tenuifolia', 43: 'cercidiphyllum_japonicum', 44: 'cercis_canadensis', 45: 'chamaecyparis_pisifera', 46: 'chamaecyparis_thyoides', 47: 'chionanthus_retusus', 48: 'chionanthus_virginicus', 49: 'cladrastis_lutea', 50: 'cornus_florida', 51: 'cornus_kousa', 52: 'cornus_mas', 53: 'crataegus_crus-galli', 54: 'crataegus_laevigata', 55: 'crataegus_phaenopyrum', 56: 'crataegus_pruinosa', 57: 'crataegus_viridis', 58: 'cryptomeria_japonica', 59: 'diospyros_virginiana', 60: 'eucommia_ulmoides', 61: 'evodia_daniellii', 62: 'fagus_grandifolia', 63: 'ficus_carica', 64: 'fraxinus_nigra', 65: 'fraxinus_pennsylvanica', 66: 'ginkgo_biloba', 67: 'gleditsia_triacanthos', 68: 'gymnocladus_dioicus', 69: 'halesia_tetraptera', 70: 'ilex_opaca', 71: 'juglans_cinerea', 72: 'juglans_nigra', 73: 'juniperus_virginiana', 74: 'koelreuteria_paniculata', 75: 'larix_decidua', 76: 'liquidambar_styraciflua', 77: 'liriodendron_tulipifera', 78: 'maclura_pomifera', 79: 'magnolia_acuminata', 80: 'magnolia_denudata', 81: 'magnolia_grandiflora', 82: 'magnolia_macrophylla', 83: 'magnolia_stellata', 84: 'magnolia_tripetala', 85: 'magnolia_virginiana', 86: 'malus_baccata', 87: 'malus_coronaria', 88: 'malus_floribunda', 89: 'malus_hupehensis', 90: 'malus_pumila', 91: 'metasequoia_glyptostroboides', 92: 'morus_alba', 93: 'morus_rubra', 94: 'nyssa_sylvatica', 95: 'ostrya_virginiana', 96: 'oxydendrum_arboreum', 97: 'paulownia_tomentosa', 98: 'phellodendron_amurense', 99: 'picea_abies', 100: 'picea_orientalis', 101: 'picea_pungens', 102: 'pinus_bungeana', 103: 'pinus_cembra', 104: 'pinus_densiflora', 105: 'pinus_echinata', 106: 'pinus_flexilis', 107: 'pinus_koraiensis', 108: 'pinus_nigra', 109: 'pinus_parviflora', 110: 'pinus_peucea', 111: 'pinus_pungens', 112: 'pinus_resinosa', 113: 'pinus_rigida', 114: 'pinus_strobus', 115: 'pinus_sylvestris', 116: 'pinus_taeda', 117: 'pinus_thunbergii', 118: 'pinus_virginiana', 119: 'pinus_wallichiana', 120: 'platanus_acerifolia', 121: 'platanus_occidentalis', 122: 'populus_deltoides', 123: 'populus_grandidentata', 124: 'populus_tremuloides', 125: 'prunus_pensylvanica', 126: 'prunus_sargentii', 127: 'prunus_serotina', 128: 'prunus_serrulata', 129: 'prunus_subhirtella', 130: 'prunus_virginiana', 131: 'prunus_yedoensis', 132: 'pseudolarix_amabilis', 133: 'ptelea_trifoliata', 134: 'pyrus_calleryana', 135: 'quercus_acutissima', 136: 'quercus_alba', 137: 'quercus_bicolor', 138: 'quercus_cerris', 139: 'quercus_coccinea', 140: 'quercus_imbricaria', 141: 'quercus_macrocarpa', 142: 'quercus_marilandica', 143: 'quercus_michauxii', 144: 'quercus_montana', 145: 'quercus_muehlenbergii', 146: 'quercus_nigra', 147: 'quercus_palustris', 148: 'quercus_phellos', 149: 'quercus_robur', 150: 'quercus_shumardii', 151: 'quercus_stellata', 152: 'quercus_velutina', 153: 'quercus_virginiana', 154: 'robinia_pseudo-acacia', 155: 'salix_babylonica', 156: 'salix_caroliniana', 157: 'salix_matsudana', 158: 'salix_nigra', 159: 'sassafras_albidum', 160: 'staphylea_trifolia', 161: 'stewartia_pseudocamellia', 162: 'styrax_japonica', 163: 'taxodium_distichum', 164: 'tilia_americana', 165: 'tilia_cordata', 166: 'tilia_europaea', 167: 'tilia_tomentosa', 168: 'tsuga_canadensis', 169: 'ulmus_americana', 170: 'ulmus_glabra', 171: 'ulmus_parvifolia', 172: 'ulmus_procera', 173: 'ulmus_pumila', 174: 'ulmus_rubra', 175: 'zelkova_serrata'}\n"
     ]
    }
   ],
   "source": [
    "label_to_num = dict(zip(labels, range(labels_len)))#标签和数字对应\n",
    "print(label_to_num)\n",
    "num_to_label = dict(zip(range(labels_len),labels))#数字和标签对应\n",
    "print(num_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个继承pytorch的dataset的数据类\n",
    "class LeavesData(Dataset):\n",
    "    def __init__(self, csv_path, file_path, mode='train', valid_ratio=0.2, resize_height=224, resize_width=224):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): csv 文件路径\n",
    "            img_path (string): 图像文件所在路径\n",
    "            mode (string): 训练模式还是测试模式\n",
    "            valid_ratio (float): 验证集比例\n",
    "        \"\"\"\n",
    "        \n",
    "        # 因为可能每张图片的大小尺寸不一致，故统一调整图片尺寸大小\n",
    "        self.resize_height = resize_height\n",
    "        self.resize_width = resize_width\n",
    "\n",
    "        self.file_path = file_path\n",
    "        self.mode = mode\n",
    "\n",
    "        # 读取 csv 文件\n",
    "        # 利用pandas读取csv文件\n",
    "        self.data_info = pd.read_csv(csv_path, header=None)  #header=None是去掉表头部分\n",
    "        # 计算 length\n",
    "        self.data_len = len(self.data_info.index) - 1\n",
    "        self.train_len = int(self.data_len * (1 - valid_ratio))\n",
    "        \n",
    "        if mode == 'train':#训练集\n",
    "            # 第一列包含图像文件的名称\n",
    "            self.train_image = self.data_info.iloc[1:self.train_len, 0].to_numpy()  #self.data_info.iloc[1:,0]表示读取第一列，从第二行开始到train_len\n",
    "            # 第二列是图像的 label\n",
    "            self.train_label = self.data_info.iloc[1:self.train_len, 1].to_numpy()\n",
    "            self.image_arr = self.train_image \n",
    "            self.label_arr = self.train_label\n",
    "        elif mode == 'valid':#测试集\n",
    "            self.valid_image = self.data_info.iloc[self.train_len:, 0].to_numpy()\n",
    "            self.valid_label = self.data_info.iloc[self.train_len:, 1].to_numpy()\n",
    "            self.image_arr = self.valid_image\n",
    "            self.label_arr = self.valid_label\n",
    "        elif mode == 'test':\n",
    "            self.test_image = self.data_info.iloc[1:, 0].to_numpy()\n",
    "            self.image_arr = self.test_image\n",
    "            \n",
    "        self.real_len = len(self.image_arr)\n",
    "\n",
    "        print('Finished reading the {} set of Leaves Dataset ({} samples found)'\n",
    "              .format(mode, self.real_len))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 从 image_arr中得到索引对应的文件名\n",
    "        single_image_name = self.image_arr[index]\n",
    "\n",
    "        # 读取图像文件\n",
    "        img_data = Image.open(self.file_path + single_image_name)\n",
    "\n",
    "        #设置好需要转换的变量，还可以包括一系列的nomarlize等等操作\n",
    "        if self.mode == 'train':\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((self.resize_height, self.resize_width)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),   #随机水平翻转 选择一个概率\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        else:\n",
    "            # valid和test不做数据增强\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((self.resize_height, self.resize_width)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        \n",
    "        img_data = transform(img_data)\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            return img_data\n",
    "        else:\n",
    "            # 得到图像的 string label\n",
    "            label = self.label_arr[index]\n",
    "            # number label\n",
    "            number_label = label_to_num[label]\n",
    "\n",
    "            return img_data, number_label  #返回每一个index对应的图片数据和对应的label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.real_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading the train set of Leaves Dataset (14681 samples found)\n",
      "Finished reading the valid set of Leaves Dataset (3672 samples found)\n",
      "Finished reading the test set of Leaves Dataset (8800 samples found)\n",
      "<__main__.LeavesData object at 0x000001AA6D473370>\n",
      "<__main__.LeavesData object at 0x000001AA43020D30>\n",
      "<__main__.LeavesData object at 0x000001AA43298460>\n"
     ]
    }
   ],
   "source": [
    "train_path = '../data/train.csv'\n",
    "test_path = '../data/test.csv'\n",
    "# csv文件中已经images的路径了，因此这里只到上一级目录\n",
    "img_path = '../data/'\n",
    "\n",
    "train_dataset = LeavesData(train_path, img_path, mode='train')\n",
    "val_dataset = LeavesData(train_path, img_path, mode='valid')\n",
    "test_dataset = LeavesData(test_path, img_path, mode='test')\n",
    "print(train_dataset)\n",
    "print(val_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_leave_img(train_dataset,val_dataset,test_dataset,batch_size):\n",
    "    \"\"\"下载叶子图片的数据集，然后将其加载到内存中\"\"\"\n",
    "    return (data.DataLoader(train_dataset, batch_size, shuffle=True,\n",
    "                            num_workers=0),\n",
    "            data.DataLoader(val_dataset, batch_size, shuffle=False,\n",
    "                            num_workers=0),\n",
    "            data.DataLoader(test_dataset, batch_size, shuffle=False,\n",
    "                            num_workers=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iter,val_iter,test_iter = load_data_leave_img(train_dataset,val_dataset,test_dataset,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个resnet模型\n",
    "class Residual(nn.Module):  #残差块\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
    "                               kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
    "                               kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
    "                                   kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)\n",
    "\n",
    "def resnet_block(input_channels, num_channels, num_residuals,\n",
    "                 first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels,\n",
    "                                use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk\n",
    "\n",
    "\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.b2 = nn.Sequential(*resnet_block(64, 64, 3, first_block=True))\n",
    "        self.b3 = nn.Sequential(*resnet_block(64, 128, 4))\n",
    "        self.b4 = nn.Sequential(*resnet_block(128, 256, 6))\n",
    "        self.b5 = nn.Sequential(*resnet_block(256, 512, 3))\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.b1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.b4(x)\n",
    "        x = self.b5(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 看一下是在cpu还是GPU上\n",
    "def get_device():\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNetModel(176)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(net,train_iter,val_iter,learning_rate,num_epochs,weight_decay,device):\n",
    "    #初始化参数\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    # 将模型移到相应device上\n",
    "    net = net.to(device)\n",
    "    net.device = device\n",
    "    #交叉熵损失\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        #模型训练模式\n",
    "        net.train()\n",
    "        #训练损失和训练精度\n",
    "        train_loss = []\n",
    "        train_accs = []\n",
    "        for batch in tqdm(train_iter):\n",
    "            imgs, labels = batch\n",
    "            #将图片和标签都移到正确的device上\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels_hat = net(imgs)\n",
    "            l = loss(labels_hat, labels)\n",
    "            #更新梯度为0\n",
    "            optimizer.zero_grad()\n",
    "            #计算参数的梯度\n",
    "            l.backward()\n",
    "            #根据梯度更新参数\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 计算当前批量的精确度\n",
    "            acc = (labels_hat.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "            # Record the loss and accuracy.\n",
    "            train_loss.append(l.item())\n",
    "            train_accs.append(acc)\n",
    "        #计算整体的训练损失和精确度\n",
    "        train_loss = sum(train_loss) / len(train_loss)\n",
    "        train_acc = sum(train_accs) / len(train_accs)\n",
    "\n",
    "        #打印结果\n",
    "        print(f\"[ Train | {epoch + 1:03d}/{num_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "\n",
    "        #模型检测模式\n",
    "        net.eval()\n",
    "        \n",
    "        valid_loss = []\n",
    "        valid_accs = []\n",
    "\n",
    "\n",
    "        for batch in tqdm(val_iter):\n",
    "            imgs, labels = batch\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                labels_hat = net(imgs)\n",
    "                \n",
    "            l = loss(labels_hat, labels)\n",
    "\n",
    "            acc = (labels_hat.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "            valid_loss.append(l.item())\n",
    "            valid_accs.append(acc)\n",
    "        \n",
    "        valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "        valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "\n",
    "        print(f\"[ Valid | {epoch + 1:03d}/{num_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "\n",
    "        if valid_acc > best_acc :\n",
    "            best_acc = valid_acc\n",
    "            torch.save(net.state_dict(), 'model_state_dict.pth')\n",
    "            print('saving model with acc {:.3f}'.format(best_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:56<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 001/030 ] loss = 3.79166, acc = 0.13246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 001/030 ] loss = 3.54311, acc = 0.16277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:55<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 002/030 ] loss = 2.64976, acc = 0.30679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 002/030 ] loss = 5.38220, acc = 0.16386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:57<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 003/030 ] loss = 2.07124, acc = 0.42490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:18<00:00, 12.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 003/030 ] loss = 2.79527, acc = 0.30598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:56<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 004/030 ] loss = 1.75155, acc = 0.50405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 12.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 004/030 ] loss = 1.68830, acc = 0.50842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:56<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 005/030 ] loss = 1.49862, acc = 0.56727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 12.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 005/030 ] loss = 1.46665, acc = 0.56440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:55<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 006/030 ] loss = 1.34656, acc = 0.60474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 006/030 ] loss = 1.45674, acc = 0.56196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:56<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 007/030 ] loss = 1.21041, acc = 0.64300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 007/030 ] loss = 1.51796, acc = 0.56658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:55<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 008/030 ] loss = 1.10301, acc = 0.67400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 008/030 ] loss = 1.51952, acc = 0.54701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:55<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 009/030 ] loss = 1.01121, acc = 0.70202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:16<00:00, 13.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 009/030 ] loss = 3.49329, acc = 0.30978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:53<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 010/030 ] loss = 0.93514, acc = 0.72212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 010/030 ] loss = 3.81665, acc = 0.29212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:55<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 011/030 ] loss = 0.85872, acc = 0.74894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:16<00:00, 13.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 011/030 ] loss = 1.33647, acc = 0.60842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:56<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 012/030 ] loss = 0.81681, acc = 0.75459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 012/030 ] loss = 0.89691, acc = 0.73071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:57<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 013/030 ] loss = 0.75982, acc = 0.77316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 013/030 ] loss = 1.05834, acc = 0.68478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:56<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 014/030 ] loss = 0.71629, acc = 0.78618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 12.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 014/030 ] loss = 1.40142, acc = 0.59022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:55<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 015/030 ] loss = 0.69437, acc = 0.79430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 12.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 015/030 ] loss = 1.38621, acc = 0.61522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:57<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 016/030 ] loss = 0.66074, acc = 0.80451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 016/030 ] loss = 3.26134, acc = 0.33179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:57<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 017/030 ] loss = 0.64986, acc = 0.80543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 017/030 ] loss = 0.81534, acc = 0.74348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:56<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 018/030 ] loss = 0.60690, acc = 0.82458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 018/030 ] loss = 1.04390, acc = 0.69348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [03:00<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 019/030 ] loss = 0.56935, acc = 0.83479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:18<00:00, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 019/030 ] loss = 1.09194, acc = 0.67609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:58<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 020/030 ] loss = 0.55142, acc = 0.83711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:18<00:00, 12.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 020/030 ] loss = 1.30091, acc = 0.63207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:54<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 021/030 ] loss = 0.53699, acc = 0.84243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 021/030 ] loss = 0.76970, acc = 0.76603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:55<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 022/030 ] loss = 0.52060, acc = 0.84513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:18<00:00, 12.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 022/030 ] loss = 1.16219, acc = 0.67772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:58<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 023/030 ] loss = 0.48762, acc = 0.86026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 023/030 ] loss = 1.07650, acc = 0.68043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:57<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 024/030 ] loss = 0.50619, acc = 0.85384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 024/030 ] loss = 0.79749, acc = 0.76114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:54<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 025/030 ] loss = 0.47116, acc = 0.86546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 025/030 ] loss = 1.32125, acc = 0.63179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:54<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 026/030 ] loss = 0.45808, acc = 0.86942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 026/030 ] loss = 0.83380, acc = 0.75435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:54<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 027/030 ] loss = 0.44923, acc = 0.87088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 027/030 ] loss = 0.69865, acc = 0.78668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:54<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 028/030 ] loss = 0.42915, acc = 0.87964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:16<00:00, 13.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 028/030 ] loss = 2.18438, acc = 0.48071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:54<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 029/030 ] loss = 0.42424, acc = 0.88148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 029/030 ] loss = 0.58950, acc = 0.81603\n",
      "saving model with acc 0.816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [02:55<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 030/030 ] loss = 0.42002, acc = 0.88243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:17<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 030/030 ] loss = 1.12573, acc = 0.68832\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs, batch_size, weight_decay= 3e-4, 30, 16,1e-3\n",
    "train_iter,val_iter,_ = load_data_leave_img(train_dataset,val_dataset,test_dataset,batch_size)\n",
    "train(net,train_iter,val_iter,lr,num_epochs,weight_decay,get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFileName = './submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ResNetModel(176)\n",
    "\n",
    "_,_,test_iter = load_data_leave_img(train_dataset,val_dataset,test_dataset,64)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('model_state_dict.pth'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for batch in tqdm(test_iter): \n",
    "    imgs = batch\n",
    "    with torch.no_grad():\n",
    "        logits = model(imgs.to(device))\n",
    "    \n",
    "    # Take the class with greatest logit as prediction and record it.\n",
    "    predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n",
    "\n",
    "preds = []\n",
    "for i in predictions:\n",
    "    preds.append(num_to_label[i])\n",
    "\n",
    "test_data = pd.read_csv('../data/test.csv')\n",
    "test_data['label'] = pd.Series(preds)\n",
    "submission = pd.concat([test_data['image'], test_data['label']], axis=1)\n",
    "submission.to_csv(saveFileName, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
